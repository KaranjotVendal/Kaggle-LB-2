{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/kfolds_CV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    fold, xtrain, xtest, ytrain, ytest = df.iloc[_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405    0\n",
      "20     0\n",
      "401    1\n",
      "567    0\n",
      "9      1\n",
      "      ..\n",
      "4      1\n",
      "495    1\n",
      "273    1\n",
      "275    0\n",
      "28     0\n",
      "Name: MGMT_value, Length: 468, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ytrain[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataRetriever(Dataset):\n",
    "    def __init__(self, patient_path, paths, targets, n_frames, img_size, transform=None):\n",
    "        self.patient_path = patient_path\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.n_frames = n_frames\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def read_video(self, vid_paths):\n",
    "        video = [load_image(path, (self.img_size, self.img_size)) for path in vid_paths]\n",
    "        if self.transform:\n",
    "            seed = random.randint(0,99999)\n",
    "            for i in range(len(video)):\n",
    "                random.seed(seed)\n",
    "                video[i] = self.transform(image=video[i])[\"image\"]\n",
    "        \n",
    "        video = [torch.tensor(frame, dtype=torch.float32) for frame in video]\n",
    "        if len(video)==0:\n",
    "            video = torch.zeros(self.n_frames, self.img_size, self.img_size)\n",
    "        else:\n",
    "            video = torch.stack(video) # T * C * H * W\n",
    "        return video\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        _id = self.paths[index]\n",
    "        patient_path = os.path.join(self.patient_path, f'{str(_id).zfill(5)}/')\n",
    "\n",
    "        channels = []\n",
    "        for t in [\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"]:\n",
    "            t_paths = sorted(\n",
    "                glob.glob(os.path.join(patient_path, t, \"*\")), \n",
    "                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n",
    "            )\n",
    "            num_samples = self.n_frames\n",
    "            if len(t_paths) < num_samples:\n",
    "                in_frames_path = t_paths\n",
    "            else:\n",
    "                in_frames_path = uniform_temporal_subsample(t_paths, num_samples)\n",
    "            \n",
    "            channel = self.read_video(in_frames_path)\n",
    "            if channel.shape[0] == 0:\n",
    "                channel = torch.zeros(num_samples, self.img_size, self.img_size)\n",
    "            channels.append(channel)\n",
    "            \n",
    "        channels = torch.stack(channels).transpose(0,1)\n",
    "        y = torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        return {\"X\": channels.float(), \"y\": y}\n",
    "\n",
    "class TestDataRetriever(Dataset):\n",
    "    def __init__(self, patient_path, paths, n_frames, img_size, transform=None):\n",
    "        self.patient_path = patient_path\n",
    "        self.paths = paths\n",
    "        self.n_frames = n_frames\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def read_video(self, vid_paths):\n",
    "        video = [load_dicom(path, self.img_size) for path in vid_paths]\n",
    "        if len(video)==0:\n",
    "            video = torch.zeros(self.n_frames, self.img_size, self.img_size)\n",
    "        else:\n",
    "            video = torch.stack(video) # T * C * H * W\n",
    "        return video\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        _id = self.paths[index]\n",
    "        patient_path = os.path.join(self.patient_path, f'{str(_id).zfill(5)}/')\n",
    "        channels = []\n",
    "        for t in [\"FLAIR\",\"T1w\", \"T1wCE\", \"T2w\"]:\n",
    "            t_paths = sorted(\n",
    "                glob.glob(os.path.join(patient_path, t, \"*\")), \n",
    "                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n",
    "            )\n",
    "            num_samples = self.n_frames\n",
    "            if len(t_paths) < num_samples:\n",
    "                in_frames_path = t_paths\n",
    "            else:\n",
    "                in_frames_path = uniform_temporal_subsample(t_paths, num_samples)\n",
    "            \n",
    "            channel = self.read_video(in_frames_path)\n",
    "            if channel.shape[0] == 0:\n",
    "                print(\"1 channel empty\")\n",
    "                channel = torch.zeros(num_samples, self.img_size, self.img_size)\n",
    "            channels.append(channel)\n",
    "        \n",
    "        channels = torch.stack(channels).transpose(0,1)\n",
    "        return {\"X\": channels.float(), \"id\": _id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "                                A.HorizontalFlip(p=0.5),\n",
    "                                A.ShiftScaleRotate(\n",
    "                                    shift_limit=0.0625, \n",
    "                                    scale_limit=0.1, \n",
    "                                    rotate_limit=10, \n",
    "                                    p=0.5\n",
    "                                ),\n",
    "                                A.RandomBrightnessContrast(p=0.5),\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = DataRetriever('../input/kfolds_CV.csv',\n",
    "            xtrain, #train_df[\"BraTS21ID\"].values, \n",
    "            ytrain, #train_df[\"MGMT_value\"].values,\n",
    "            n_frames=10,\n",
    "            img_size=112,\n",
    "            transform=train_transform\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainset[\u001b[39m'\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "Cell \u001b[0;32mIn[10], line 29\u001b[0m, in \u001b[0;36mDataRetriever.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[0;32m---> 29\u001b[0m     _id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpaths[index]\n\u001b[1;32m     30\u001b[0m     patient_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatient_path, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(_id)\u001b[39m.\u001b[39mzfill(\u001b[39m5\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m     channels \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "trainset['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
